{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3edd251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "####copied from course\n",
    "import string\n",
    "\n",
    "def z_array(s):\n",
    "    \"\"\" Use Z algorithm (Gusfield theorem 1.4.1) to preprocess s \"\"\"\n",
    "    assert len(s) > 1\n",
    "    z = [len(s)] + [0] * (len(s)-1)\n",
    "    # Initial comparison of s[1:] with prefix\n",
    "    for i in range(1, len(s)):\n",
    "        if s[i] == s[i-1]:\n",
    "            z[1] += 1\n",
    "        else:\n",
    "            break\n",
    "    r, l = 0, 0\n",
    "    if z[1] > 0:\n",
    "        r, l = z[1], 1\n",
    "    for k in range(2, len(s)):\n",
    "        assert z[k] == 0\n",
    "        if k > r:\n",
    "            # Case 1\n",
    "            for i in range(k, len(s)):\n",
    "                if s[i] == s[i-k]:\n",
    "                    z[k] += 1\n",
    "                else:\n",
    "                    break\n",
    "            r, l = k + z[k] - 1, k\n",
    "        else:\n",
    "            # Case 2\n",
    "            # Calculate length of beta\n",
    "            nbeta = r - k + 1\n",
    "            zkp = z[k - l]\n",
    "            if nbeta > zkp:\n",
    "                # Case 2a: Zkp wins\n",
    "                z[k] = zkp\n",
    "            else:\n",
    "                # Case 2b: Compare characters just past r\n",
    "                nmatch = 0\n",
    "                for i in range(r+1, len(s)):\n",
    "                    if s[i] == s[i - k]:\n",
    "                        nmatch += 1\n",
    "                    else:\n",
    "                        break\n",
    "                l, r = k, r + nmatch\n",
    "                z[k] = r - k + 1\n",
    "    return z\n",
    "\n",
    "\n",
    "def n_array(s):\n",
    "    \"\"\" Compile the N array (Gusfield theorem 2.2.2) from the Z array \"\"\"\n",
    "    return z_array(s[::-1])[::-1]\n",
    "\n",
    "\n",
    "def big_l_prime_array(p, n):\n",
    "    \"\"\" Compile L' array (Gusfield theorem 2.2.2) using p and N array.\n",
    "        L'[i] = largest index j less than n such that N[j] = |P[i:]| \"\"\"\n",
    "    lp = [0] * len(p)\n",
    "    for j in range(len(p)-1):\n",
    "        i = len(p) - n[j]\n",
    "        if i < len(p):\n",
    "            lp[i] = j + 1\n",
    "    return lp\n",
    "\n",
    "\n",
    "def big_l_array(p, lp):\n",
    "    \"\"\" Compile L array (Gusfield theorem 2.2.2) using p and L' array.\n",
    "        L[i] = largest index j less than n such that N[j] >= |P[i:]| \"\"\"\n",
    "    l = [0] * len(p)\n",
    "    l[1] = lp[1]\n",
    "    for i in range(2, len(p)):\n",
    "        l[i] = max(l[i-1], lp[i])\n",
    "    return l\n",
    "\n",
    "\n",
    "def small_l_prime_array(n):\n",
    "    \"\"\" Compile lp' array (Gusfield theorem 2.2.4) using N array. \"\"\"\n",
    "    small_lp = [0] * len(n)\n",
    "    for i in range(len(n)):\n",
    "        if n[i] == i+1:  # prefix matching a suffix\n",
    "            small_lp[len(n)-i-1] = i+1\n",
    "    for i in range(len(n)-2, -1, -1):  # \"smear\" them out to the left\n",
    "        if small_lp[i] == 0:\n",
    "            small_lp[i] = small_lp[i+1]\n",
    "    return small_lp\n",
    "\n",
    "\n",
    "def good_suffix_table(p):\n",
    "    \"\"\" Return tables needed to apply good suffix rule. \"\"\"\n",
    "    n = n_array(p)\n",
    "    lp = big_l_prime_array(p, n)\n",
    "    return lp, big_l_array(p, lp), small_l_prime_array(n)\n",
    "\n",
    "\n",
    "def good_suffix_mismatch(i, big_l_prime, small_l_prime):\n",
    "    \"\"\" Given a mismatch at offset i, and given L/L' and l' arrays,\n",
    "        return amount to shift as determined by good suffix rule. \"\"\"\n",
    "    length = len(big_l_prime)\n",
    "    assert i < length\n",
    "    if i == length - 1:\n",
    "        return 0\n",
    "    i += 1  # i points to leftmost matching position of P\n",
    "    if big_l_prime[i] > 0:\n",
    "        return length - big_l_prime[i]\n",
    "    return length - small_l_prime[i]\n",
    "\n",
    "\n",
    "def good_suffix_match(small_l_prime):\n",
    "    \"\"\" Given a full match of P to T, return amount to shift as\n",
    "        determined by good suffix rule. \"\"\"\n",
    "    return len(small_l_prime) - small_l_prime[1]\n",
    "\n",
    "\n",
    "def dense_bad_char_tab(p, amap):\n",
    "    \"\"\" Given pattern string and list with ordered alphabet characters, create\n",
    "        and return a dense bad character table.  Table is indexed by offset\n",
    "        then by character. \"\"\"\n",
    "    tab = []\n",
    "    nxt = [0] * len(amap)\n",
    "    for i in range(0, len(p)):\n",
    "        c = p[i]\n",
    "        assert c in amap\n",
    "        tab.append(nxt[:])\n",
    "        nxt[amap[c]] = i+1\n",
    "    return tab\n",
    "\n",
    "\n",
    "class BoyerMoore(object):\n",
    "    \"\"\" Encapsulates pattern and associated Boyer-Moore preprocessing. \"\"\"\n",
    "    \n",
    "    def __init__(self, p, alphabet='ACGT'):\n",
    "        self.p = p\n",
    "        self.alphabet = alphabet\n",
    "        # Create map from alphabet characters to integers\n",
    "        self.amap = {}\n",
    "        for i in range(len(self.alphabet)):\n",
    "            self.amap[self.alphabet[i]] = i\n",
    "        # Make bad character rule table\n",
    "        self.bad_char = dense_bad_char_tab(p, self.amap)\n",
    "        # Create good suffix rule table\n",
    "        _, self.big_l, self.small_l_prime = good_suffix_table(p)\n",
    "    \n",
    "    def bad_character_rule(self, i, c):\n",
    "        \"\"\" Return # skips given by bad character rule at offset i \"\"\"\n",
    "        assert c in self.amap\n",
    "        ci = self.amap[c]\n",
    "        assert i > (self.bad_char[i][ci]-1)\n",
    "        return i - (self.bad_char[i][ci]-1)\n",
    "    \n",
    "    def good_suffix_rule(self, i):\n",
    "        \"\"\" Given a mismatch at offset i, return amount to shift\n",
    "            as determined by (weak) good suffix rule. \"\"\"\n",
    "        length = len(self.big_l)\n",
    "        assert i < length\n",
    "        if i == length - 1:\n",
    "            return 0\n",
    "        i += 1  # i points to leftmost matching position of P\n",
    "        if self.big_l[i] > 0:\n",
    "            return length - self.big_l[i]\n",
    "        return length - self.small_l_prime[i]\n",
    "    \n",
    "    def match_skip(self):\n",
    "        \"\"\" Return amount to shift in case where P matches T \"\"\"\n",
    "        return len(self.small_l_prime) - self.small_l_prime[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d7fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boyer_moore(p, p_bm, t):\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            if not p[j] == t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b4ad0e",
   "metadata": {},
   "source": [
    " implement versions of the naive exact matching and Boyer-Moore algorithms that additionally count and return (a) the number of character comparisons performed and (b) the number of alignments tried. Roughly speaking, these measure how much work the two different algorithms are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca9a3c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive matching algorithm - try all lineups of pattern against string\n",
    "def naive_with_counts(p, t):\n",
    "    occurrences = []\n",
    "    num_alignments = 0\n",
    "    num_character_comparisons = 0\n",
    "    for i in range(len(t) - len(p) + 1): # loop over alignments\n",
    "        match = True\n",
    "        num_alignments += 1\n",
    "        for j in range(len(p)):          # loop over characters\n",
    "            num_character_comparisons += 1\n",
    "            if t[i + j] != p[j]:         # compare characters\n",
    "                match = False            # mismatch; reject alignment\n",
    "                break\n",
    "        if match:\n",
    "            occurrences.append(i)         # all chars matched; record\n",
    "    return occurrences, num_alignments, num_character_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6a5f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] 41 46\n"
     ]
    }
   ],
   "source": [
    "# example 1\n",
    "p = 'word'\n",
    "t = 'there would have been a time for such a word'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b750a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 19] 20 35\n"
     ]
    }
   ],
   "source": [
    "p = 'needle'\n",
    "t = 'needle need noodle needle'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b8ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boyer_moore_with_counts(p, p_bm, t):\n",
    "    i = 0\n",
    "    occurrences = []\n",
    "    num_alignments = 0\n",
    "    num_character_comparisons = 0\n",
    "    while i < len(t) - len(p) + 1:\n",
    "        num_alignments += 1\n",
    "        shift = 1\n",
    "        mismatched = False\n",
    "        for j in range(len(p)-1, -1, -1):\n",
    "            num_character_comparisons += 1\n",
    "            if not p[j] == t[i+j]:\n",
    "                skip_bc = p_bm.bad_character_rule(j, t[i+j])\n",
    "                skip_gs = p_bm.good_suffix_rule(j)\n",
    "                shift = max(shift, skip_bc, skip_gs)\n",
    "                mismatched = True\n",
    "                break\n",
    "        if not mismatched:\n",
    "            occurrences.append(i)\n",
    "            skip_gs = p_bm.match_skip()\n",
    "            shift = max(shift, skip_gs)\n",
    "        i += shift\n",
    "    return occurrences, num_alignments, num_character_comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24167b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] 12 15\n"
     ]
    }
   ],
   "source": [
    "# example 1\n",
    "p = 'word'\n",
    "t = 'there would have been a time for such a word'\n",
    "lowercase_alphabet = 'abcdefghijklmnopqrstuvwxyz '\n",
    "p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10d27e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 19] 5 18\n"
     ]
    }
   ],
   "source": [
    "# example 2\n",
    "p = 'needle'\n",
    "t = 'needle need noodle needle'\n",
    "p_bm = BoyerMoore(p, lowercase_alphabet)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, t)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58695027",
   "metadata": {},
   "outputs": [],
   "source": [
    "### the questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13d6a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGenome(filename):\n",
    "    genome = ''\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if not line[0] == \">\":\n",
    "                # rstrip removes trailing whitespace\n",
    "                genome += line.rstrip()\n",
    "    return genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5503bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrc\n",
      "syswgetrc = C:\\Program Files (x86)\\GnuWin32/etc/wgetrc\n",
      "--2022-02-10 14:32:05--  http://d28rh4a8wq0iu5.cloudfront.net/ads1/data/chr1.GRCh38.excerpt.fasta\n",
      "Resolving d28rh4a8wq0iu5.cloudfront.net... 108.138.225.105, 108.138.225.70, 108.138.225.59, ...\n",
      "Connecting to d28rh4a8wq0iu5.cloudfront.net|108.138.225.105|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 810105 (791K) [application/octet-stream]\n",
      "Saving to: `chr1.GRCh38.excerpt.fasta'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  6%  589K 1s\n",
      "    50K .......... .......... .......... .......... .......... 12% 1.34M 1s\n",
      "   100K .......... .......... .......... .......... .......... 18% 1016K 1s\n",
      "   150K .......... .......... .......... .......... .......... 25% 2.72M 1s\n",
      "   200K .......... .......... .......... .......... .......... 31%  914K 1s\n",
      "   250K .......... .......... .......... .......... .......... 37% 1.16M 0s\n",
      "   300K .......... .......... .......... .......... .......... 44% 1.71M 0s\n",
      "   350K .......... .......... .......... .......... .......... 50% 2.40M 0s\n",
      "   400K .......... .......... .......... .......... .......... 56% 1.96M 0s\n",
      "   450K .......... .......... .......... .......... .......... 63% 1.81M 0s\n",
      "   500K .......... .......... .......... .......... .......... 69% 1.16M 0s\n",
      "   550K .......... .......... .......... .......... .......... 75%  875K 0s\n",
      "   600K .......... .......... .......... .......... .......... 82% 2.01M 0s\n",
      "   650K .......... .......... .......... .......... .......... 88% 2.62M 0s\n",
      "   700K .......... .......... .......... .......... .......... 94% 3.15M 0s\n",
      "   750K .......... .......... .......... .......... .         100% 1.75M=0.6s\n",
      "\n",
      "2022-02-10 14:32:07 (1.36 MB/s) - `chr1.GRCh38.excerpt.fasta' saved [810105/810105]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!\"C:\\Program Files (x86)\\GnuWin32\\bin\\wget\" --no-check-certificate http://d28rh4a8wq0iu5.cloudfront.net/ads1/data/chr1.GRCh38.excerpt.fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3dad823",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome = readGenome('chr1.GRCh38.excerpt.fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdd77913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922] 799954 984143\n"
     ]
    }
   ],
   "source": [
    "# questions 1 and 2\n",
    "p = 'GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG'\n",
    "occurrences, num_alignments, num_character_comparisons = naive_with_counts(p, genome)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f36cc69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922] 127974 165191\n"
     ]
    }
   ],
   "source": [
    "# question 3\n",
    "p = 'GGCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGG'\n",
    "p_bm = BoyerMoore(p)\n",
    "occurrences, num_alignments, num_character_comparisons = boyer_moore_with_counts(p, p_bm, genome)\n",
    "print(occurrences, num_alignments, num_character_comparisons)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f336f6e1",
   "metadata": {},
   "source": [
    "## index assisted approximate matching\n",
    "Implement the pigeonhole principle using Index to find exact matches for the partitions. Assume P always has length 24, and that we are looking for approximate matches with up to 2 mismatches (substitutions). We will use an 8-mer index.  \n",
    "Write a function that, given a length-24 pattern P and given an Index object built on 8-mers, finds all approximate occurrences of P within T with up to 2 mismatches. Insertions and deletions are not allowed. Don't consider any reverse complements.\n",
    "\n",
    "How many times does the string GGCGCGGTGGCTCACGCCTGTAAT, which is derived from a human Alu sequence, occur with up to 2 substitutions in the excerpt of human chromosome 1?  (Don't consider reverse complements here.)\n",
    "\n",
    "Hint 1: Multiple index hits might direct you to the same match multiple times, but be careful not to count a match more than once.\n",
    "\n",
    "Hint 2: You can check your work by comparing the output of your new function to that of the naive_2mm function implemented in the previous module.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e85a22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "class Index(object):\n",
    "    def __init__(self, t, k):\n",
    "        ''' Create index from all substrings of size 'length' '''\n",
    "        self.k = k  # k-mer length (k)\n",
    "        self.index = []\n",
    "        for i in range(len(t) - k + 1):  # for each k-mer\n",
    "            self.index.append((t[i:i+k], i))  # add (k-mer, offset) pair\n",
    "        self.index.sort()  # alphabetize by k-mer\n",
    "    \n",
    "    def query(self, p):\n",
    "        ''' Return index hits for first k-mer of P '''\n",
    "        kmer = p[:self.k]  # query with first k-mer\n",
    "        i = bisect.bisect_left(self.index, (kmer, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != kmer:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "091e1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexed_approx_match(p, t, index, n):\n",
    "    segment_length = round(len(p) / (n+1))\n",
    "    all_matches = set()\n",
    "    index_hits = 0\n",
    "    for i in range(n+1):\n",
    "        start = i*segment_length\n",
    "        end = min((i+1)*segment_length, len(p))\n",
    "        #print(\"Start,  end and query are {} {} {} \\n\".format(start, end, p[start:end]))\n",
    "        matches = index.query(p[start:end])\n",
    "        index_hits += len(matches)\n",
    "        #print(\"Matches are {} \\n\".format(matches))\n",
    "        for m in matches:\n",
    "                if m < start or m-start+len(p) > len(t):\n",
    "                    continue\n",
    "                \n",
    "                mismatches = 0\n",
    "                for j in range(0,start):\n",
    "                    if not p[j] == t[m-start+j]:\n",
    "                        mismatches += 1\n",
    "                        if mismatches > n:\n",
    "                            break\n",
    "            \n",
    "                for j in range(end, len(p)):\n",
    "                    if not p[j] == t[m-start+j]:\n",
    "                        mismatches += 1\n",
    "                        if mismatches > n:\n",
    "                            break\n",
    "                        \n",
    "                if mismatches <= n:\n",
    "                    if m - start not in all_matches:\n",
    "                        all_matches.add(m - start)\n",
    "                \n",
    "    return sorted(list(all_matches)), index_hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "14f31f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmers\n",
    "k = 8\n",
    "index = Index(genome, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0a5c1ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([56922, 84641, 147558, 160162, 160729, 191452, 262042, 273669, 364263, 421221, 429299, 465647, 551134, 635931, 657496, 681737, 717706, 724927, 747359], 90)\n"
     ]
    }
   ],
   "source": [
    "p = 'GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "matchie = indexed_approx_match(p, t, index, 2)\n",
    "print(matchie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "34fc4375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(matchie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f32d5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_2mm(p, t):\n",
    "    occurrences = []\n",
    "    for i in range(len(t) - len(p) + 1): # loop over alignments\n",
    "        match = True\n",
    "        mismatches = 0\n",
    "        for j in range(len(p)):          # loop over characters\n",
    "            if t[i + j] != p[j]:         # compare characters\n",
    "                mismatches += 1          # advance the number of mismatches\n",
    "                if mismatches > 2:\n",
    "                    match = False            # mismatch; reject alignment\n",
    "                    break\n",
    "        if match:\n",
    "            occurrences.append(i)         # all chars matched; record\n",
    "    return occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec4d5879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56922, 84641, 147558, 160162, 160729, 191452, 262042, 273669, 364263, 421221, 429299, 465647, 551134, 635931, 657496, 681737, 717706, 724927, 747359]\n"
     ]
    }
   ],
   "source": [
    "gg = naive_2mm(p, genome)\n",
    "print(gg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa26d120",
   "metadata": {},
   "source": [
    "Question 6\n",
    "Let's examine whether there is a benefit to using an index built using subsequences of T rather than substrings, as we discussed in the \"Variations on k-mer indexes\" video.  We'll consider subsequences involving every N characters.  For example, if we split \\verb|ATATAT|ATATAT into two substring partitions, we would get partitions \\verb|ATA|ATA (the first half) and \\verb|TAT|TAT (second half).  But if we split \\verb|ATATAT|ATATAT into two  subsequences  by taking every other character, we would get \\verb|AAA|AAA (first, third and fifth characters) and \\verb|TTT|TTT (second, fourth and sixth).\n",
    "\n",
    "Another way to visualize this is using numbers to show how each character of P is allocated to a partition.  Splitting a length-6 pattern into two substrings could be represented as \\verb|111222|111222, and splitting into two subsequences of every other character could be represented as \\verb|121212|121212"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a107bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "   \n",
    "class SubseqIndex(object):\n",
    "    \"\"\" Holds a subsequence index for a text T \"\"\"\n",
    "    \n",
    "    def __init__(self, t, k, ival):\n",
    "        \"\"\" Create index from all subsequences consisting of k characters\n",
    "            spaced ival positions apart.  E.g., SubseqIndex(\"ATAT\", 2, 2)\n",
    "            extracts (\"AA\", 0) and (\"TT\", 1). \"\"\"\n",
    "        self.k = k  # num characters per subsequence extracted\n",
    "        self.ival = ival  # space between them; 1=adjacent, 2=every other, etc\n",
    "        self.index = []\n",
    "        self.span = 1 + ival * (k - 1)\n",
    "        for i in range(len(t) - self.span + 1):  # for each subseq\n",
    "            self.index.append((t[i:i+self.span:ival], i))  # add (subseq, offset)\n",
    "        self.index.sort()  # alphabetize by subseq\n",
    "    \n",
    "    def query(self, p):\n",
    "        \"\"\" Return index hits for first subseq of p \"\"\"\n",
    "        subseq = p[:self.span:self.ival]  # query with first subseq\n",
    "        i = bisect.bisect_left(self.index, (subseq, -1))  # binary search\n",
    "        hits = []\n",
    "        while i < len(self.index):  # collect matching index entries\n",
    "            if self.index[i][0] != subseq:\n",
    "                break\n",
    "            hits.append(self.index[i][1])\n",
    "            i += 1\n",
    "        return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ac367cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('AAA', 0), ('TTT', 1)]\n"
     ]
    }
   ],
   "source": [
    "ind = SubseqIndex('ATATAT', 3, 2)\n",
    "print(ind.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fbe8c6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "p = 'TTATAT'\n",
    "print(ind.query(p[0:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "250dec91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(ind.query(p[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e5fc973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_subseq(p, t, index):\n",
    "    # mismatches\n",
    "    n = 2\n",
    "    ispan = 2\n",
    "    k = 8\n",
    "    span = k + ((k - 1)*ispan)\n",
    "    num_tries = len(p) - span + 1\n",
    "    index_hits = 0\n",
    "    all_matches = set()\n",
    "    for i in range(num_tries):\n",
    "        print(\"query string is {}\\n\".format(p[i:]))\n",
    "        matches = index.query(p[i:])\n",
    "        index_hits += len(matches)\n",
    "        for m in matches:\n",
    "            if m-i+len(p) > len(t):\n",
    "                    continue\n",
    "            mismatches = 0\n",
    "            for j in range(len(p)):\n",
    "                # print(\"pattern point: {}  pattern letter:{}  text point:{}  text letter:{}\\n\".format(j, p[j], m+j-i, t[m+j-i]))\n",
    "                if not p[j] == t[m+j-i]:\n",
    "                    mismatches += 1\n",
    "                    if mismatches > n:\n",
    "                        break\n",
    "            if mismatches <= n:\n",
    "                if m - i not in all_matches:\n",
    "                    all_matches.add(m - i)           \n",
    "                    \n",
    "\n",
    "    return sorted(list(all_matches)), index_hits\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5ef63d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'to-morrow and to-morrow and to-morrow creeps in this petty pace'\n",
    "p = 'to-morrow and to-morrow '\n",
    "subseq_ind = SubseqIndex(t, 8, 3)\n",
    "#occurrences, num_index_hits = query_subseq(p, t, subseq_ind)\n",
    "#matches = subseq_ind.query(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ca45e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query string is to-morrow and to-morrow \n",
      "\n",
      "query string is o-morrow and to-morrow \n",
      "\n",
      "query string is -morrow and to-morrow \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0, 14], 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_subseq(p, t, subseq_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88ecfa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = open('pg1110.txt').read()\n",
    "p = 'English measure backward'\n",
    "subseq_ind = SubseqIndex(t, 8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "72668cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query string is English measure backward\n",
      "\n",
      "query string is nglish measure backward\n",
      "\n",
      "query string is glish measure backward\n",
      "\n"
     ]
    }
   ],
   "source": [
    "occurrences, num_index_hits = query_subseq(p, t, subseq_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f6e990e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[132576]\n"
     ]
    }
   ],
   "source": [
    "print(occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c7c69a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(num_index_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80bd7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q 6 - genome\n",
    "subseq_ind = SubseqIndex(genome, 8, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "949830a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query string is GGCGCGGTGGCTCACGCCTGTAAT\n",
      "\n",
      "query string is GCGCGGTGGCTCACGCCTGTAAT\n",
      "\n",
      "query string is CGCGGTGGCTCACGCCTGTAAT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p = 'GGCGCGGTGGCTCACGCCTGTAAT'\n",
    "occurrences, num_index_hits = query_subseq(p, genome, subseq_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ca5cbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print(num_index_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9796475c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
